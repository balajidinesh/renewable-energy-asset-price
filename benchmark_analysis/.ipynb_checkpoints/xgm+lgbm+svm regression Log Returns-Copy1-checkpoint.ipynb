{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128e0c68-301d-4d0c-a90f-6951f31a70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebbbfe8-5f9c-4e6a-a74d-b825824a84e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 09:22:15.572807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 09:22:15.581703: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 09:22:15.584245: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 09:22:15.591504: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 09:22:16.222363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy.special import expit\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle as sklearn_shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, LSTM, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# from misc_modules import dm_test, plot_double_standard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f37ca-5b1f-409c-b2af-0a375ad37898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d41fe4-d030-459a-a604-695839bfc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "etfs = ['ICLN', 'PBD', 'QCLN']  # ETF symbols\n",
    "sequence_size = 4  # Number of time steps in sequence\n",
    "cross_window = 5  # Number of cross-validation windows\n",
    "\n",
    "lags = [1]\n",
    "predType = 'ahead_Return'\n",
    "predLabel = 'Log-Return'\n",
    "# predType = 'ahead_mvol'\n",
    "# predLabel = 'Moving Avg Volatility'\n",
    "pred_size=250\n",
    "model_name = f'reg-{predType}'\n",
    "\n",
    "save_path = '../results'\n",
    "data_path = '../data'\n",
    "\n",
    "sent_dict =  {\n",
    "    'SENT': [ 'log_return', 'log_navR', 'GT_VAL_SENT', 'INV_VAL_SENT','d1-inv','d2-gt'],\n",
    "    'NO_SENT': ['log_return', 'log_navR']\n",
    "}\n",
    " \n",
    "\n",
    "\n",
    "# {\n",
    "#     'SENT': ['MAvol', 'GT_VAL_SENT_MVOL', 'INV_VAL_SENT_MVOL'],\n",
    "#     'NO_SENT': ['MAvol']\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0beab59-331f-4a68-aea8-56b34bbf5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_loss(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "\n",
    "class model:\n",
    "    def __init__(self, model_type, input_shape=None):\n",
    "        self.model_type = model_type\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._choose_model()\n",
    "\n",
    "    def _choose_model(self):\n",
    "        \"\"\"Choose and instantiate the model based on the provided model type.\"\"\"\n",
    "        if self.model_type == 'svr':\n",
    "            return SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "        elif self.model_type == 'random_forest':\n",
    "            return RandomForestRegressor(n_estimators=100, max_depth=None, min_samples_split=2, random_state=42)\n",
    "        elif self.model_type == 'xgboost':\n",
    "            return xgb.XGBRegressor(learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8, random_state=42)\n",
    "        elif self.model_type == 'lightgbm':\n",
    "            return lgb.LGBMRegressor(num_leaves=31, learning_rate=0.01, n_estimators=100, bagging_fraction=0.8, random_state=42)\n",
    "        elif self.model_type == 'catboost':\n",
    "            return CatBoostRegressor(iterations=100, depth=6, learning_rate=0.1, verbose=0, random_state=42)\n",
    "        elif self.model_type == 'cnnlstm':\n",
    "            if self.input_shape is None:\n",
    "                raise ValueError(\"input_shape must be provided for cnnlstm model.\")\n",
    "            return self._build_cnn_lstm_model()\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid model type: {self.model_type}\")\n",
    "\n",
    "    def _build_cnn_lstm_model(self):\n",
    "        \"\"\"Build the CNN-LSTM model for time series or sequence data.\"\"\"\n",
    "        Timesteps, No_Features = self.input_shape\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(Timesteps, No_Features)))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(LSTM(32, activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(8))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss=root_mean_squared_loss, metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X_train, y_train,epochs=100, batch_size=32, validation_split=0.2,shuffle=True):\n",
    "        \"\"\"Fit the model depending on the type.\"\"\"\n",
    "\n",
    "        \n",
    "        if self.model_type in ['svr', 'random_forest', 'xgboost', 'lightgbm', 'catboost']:\n",
    "            if shuffle:\n",
    "                X_train, y_train = sklearn_shuffle(X_train, y_train, random_state=42)\n",
    "            self.model.fit(X_train, y_train)\n",
    "        elif self.model_type == 'cnnlstm':\n",
    "            X_train = X_train.reshape(-1, *self.input_shape)\n",
    "            # early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            self.model.fit(X_train, y_train, epochs=epochs, verbose=False,shuffle=shuffle)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using the chosen model.\"\"\"\n",
    "        if self.model_type in ['svr', 'random_forest', 'xgboost', 'lightgbm', 'catboost']:\n",
    "            return self.model.predict(X)\n",
    "        elif self.model_type == 'cnnlstm':\n",
    "            X = X.reshape(-1, *self.input_shape)\n",
    "            return self.model.predict(X, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6dab091-e5cb-4d89-b6df-c6b29d36b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(file, lag):\n",
    "    data = pd.read_csv(f\"{data_path}/{file}/{file}_INPUT.csv\")\n",
    "    data['ahead_Return'] = data['log_return'].shift(-1 * lag)\n",
    "    data['ahead_vol'] = data['Garchvol'].shift(-1 * lag)\n",
    "    data['ahead_mvol'] = data['MAvol'].shift(-1*(lag))\n",
    "    data = data[:-1 * lag]  # Drop rows corresponding to lag\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "# Create sequences of input data\n",
    "def sequences(X, y, timesteps):\n",
    "    \"\"\"\n",
    "    Generate sequences for time series models.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    alpha, beta = [], []\n",
    "    n = timesteps\n",
    "    for i in range(X.shape[0]):\n",
    "        if i < n - 1:\n",
    "            continue\n",
    "        alpha.append(X[i - (n - 1):i + 1])\n",
    "        beta.append(y[i])\n",
    "\n",
    "    return np.asarray(alpha), np.asarray(beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d22e89-e6f7-4e26-ad03-448313810971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define helper functions\n",
    "def concat_results_and_mean(arrays):\n",
    "    \"\"\"\n",
    "    Concatenate and compute mean across all arrays.\n",
    "    \"\"\"\n",
    "    new_arrays = [np.array(single_arr).reshape(-1) for single_arr in arrays]\n",
    "    mean_array = np.mean(new_arrays, axis=0)\n",
    "    return mean_array\n",
    "\n",
    "def getanalysis(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate MAE and Directional Accuracy.\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    da = directional_accuracy(y_true, y_pred)\n",
    "    return mae, da\n",
    "\n",
    "def directional_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Directional Accuracy (DA).\n",
    "    \"\"\"\n",
    "\n",
    "    if predType == 'ahead_Return' :\n",
    "        correct_directions = np.sign(y_true) == np.sign(y_pred)\n",
    "    else :\n",
    "        correct_directions = np.sign(y_true[1:] - y_true[:-1]) == np.sign(y_pred[1:] - y_pred[:-1])\n",
    "    \n",
    "    return np.mean(correct_directions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f94621-45ab-4b05-8f5d-120bd87444fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_etfs(etfs, predType, data_path):\n",
    "    for etf in etfs:\n",
    "        # Fetch the data\n",
    "        data = fetch(etf, 1)\n",
    "        \n",
    "        # Display basic info about the dataset\n",
    "        # print(f\"\\nBasic Info for {etf}:\\n\", data.info())\n",
    "\n",
    "        # Display descriptive statistics for the specified prediction type\n",
    "        print(f\"\\nDescriptive Statistics for '{predType}' column in {etf}:\\n\")\n",
    "        stats = pd.DataFrame(data[predType]).describe()\n",
    "        print(stats)\n",
    "\n",
    "        # Visualize distribution of the specified prediction type using a histogram\n",
    "        plt.figure(figsize=(7, 6))\n",
    "        sns.histplot(data[predType], kde=True, color='blue')\n",
    "        plt.title(f'Distribution of {predType} for {etf}')\n",
    "        plt.show()\n",
    "\n",
    "        # Visualize boxplot for the specified prediction type\n",
    "        plt.figure(figsize=(7, 6))\n",
    "        sns.boxplot(x=data[predType], color='blue')\n",
    "        plt.title(f'Boxplot for {predType} for {etf}')\n",
    "        plt.show()\n",
    "\n",
    "# Call the function\n",
    "# analyze_etfs(etfs, predType, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8824cfaf-ca5f-4670-9cb1-f31ae70074e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_train(model,X ,Y , train_window=500, test_window = 10,  pred_size=pred_size,sequence_size=sequence_size) :\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # .reshape(X[:-pred_size].shape[0],1,sequence_size,-1)\n",
    "    model.fit(X[:-pred_size], Y[:-pred_size], epochs=200)\n",
    "\n",
    "    if model.model_type == 'cnnlstm' : \n",
    "        # tw_start and tw_end , means training window start index and end index\n",
    "        for tw_end in range(X.shape[0] - pred_size, X.shape[0], 10):\n",
    "            tw_start = tw_end - train_window\n",
    "    \n",
    "            X_train, y_train = X[tw_start:tw_end], Y[tw_start:tw_end]\n",
    "            # X_train = X_train.reshape(X_train.shape[0],1,sequence_size,-1)\n",
    "            model.fit(X_train, y_train, epochs=50)\n",
    "    \n",
    "            test = X[tw_end:tw_end+test_window]  #.reshape(X[tw_end:tw_end+test_window].shape[0],1,sequence_size,-1)\n",
    "            preds = model.predict(test)\n",
    "            result.extend(preds)\n",
    "            print(tw_end, end=' ')\n",
    "    else :\n",
    "        result.extend(model.predict(X[-pred_size:]))\n",
    "\n",
    "    rmse_val = root_mean_squared_loss(Y[-pred_size:].reshape(-1), np.array(result).reshape(-1))\n",
    "\n",
    "    print(f\"model RMSE = {rmse_val}\")\n",
    "\n",
    "    return np.array(result), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf286399-6ea4-4e59-b2a2-0c1b290b84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(etf, sequence_size, cross_window, model_type, sent_cols, no_sent_cols):\n",
    "    lag = 1\n",
    "    data = fetch(etf, lag) \n",
    "\n",
    "    SENT_X = data[sent_cols]\n",
    "    # Y = data[[predType]]  \n",
    "    NO_SENT_X = data[no_sent_cols]\n",
    "    \n",
    "    Y = np.array(data[[predType]])  \n",
    "\n",
    "    SENT_X, SENT_Y = sequences(SENT_X, Y, timesteps=sequence_size)\n",
    "    NO_SENT_X, NO_SENT_Y = sequences(NO_SENT_X, Y, timesteps=sequence_size)\n",
    "\n",
    "\n",
    "    sent_shape = SENT_X.shape[1:]\n",
    "    no_sent_shape = NO_SENT_X.shape[1:]\n",
    "\n",
    "    sent_model = model(model_type,sent_shape)\n",
    "    no_sent_model = model(model_type,no_sent_shape)\n",
    "\n",
    "        # machine learning regression models\n",
    "    SENT_X = SENT_X.reshape(SENT_X.shape[0], -1)\n",
    "    NO_SENT_X = NO_SENT_X.reshape(NO_SENT_X.shape[0], -1)\n",
    "    SENT_Y = SENT_Y.reshape(-1,)\n",
    "    NO_SENT_Y = NO_SENT_Y.reshape(-1,)\n",
    "\n",
    "\n",
    "    Y_PRED = Y[-pred_size:]  # Actual values for the prediction window\n",
    "    sent_predictions, no_sent_predictions = [], []\n",
    "    act_values = Y_PRED  # Actual values for this window\n",
    "    \n",
    "    # Perform cross validation over cross_window\n",
    "    for k in range(cross_window):\n",
    "\n",
    "        # Train and predict for SENT model\n",
    "        sent_pred, sent_model = sliding_window_train(sent_model,SENT_X, SENT_Y)\n",
    "        no_sent_pred, no_sent_model = sliding_window_train(sent_model,SENT_X, SENT_Y)\n",
    "\n",
    "        sent_predictions.append(sent_pred)\n",
    "        no_sent_predictions.append(no_sent_pred)\n",
    "\n",
    "        mae_sent_temp, da_sent_temp = getanalysis(act_values, sent_pred)\n",
    "        mae_no_sent_temp, da_no_sent_temp = getanalysis(act_values, no_sent_pred)\n",
    "    \n",
    "        # Print metrics for the current ETF\n",
    "        print(etf , {\n",
    "            \"sent\": {\"mae\": mae_sent_temp, \"da\": da_sent_temp},\n",
    "            \"no_sent\": {\"mae\": mae_no_sent_temp, \"da\": da_no_sent_temp}\n",
    "        })\n",
    "    \n",
    "\n",
    "    mean_sent = concat_results_and_mean(sent_predictions)  # Mean predictions for SENT\n",
    "    mean_no_sent = concat_results_and_mean(no_sent_predictions)  # Mean predictions for NO_SENT\n",
    "\n",
    "    # Get prediction metrics for SENT and NO_SENT\n",
    "    mae_sent, da_sent = getanalysis(act_values, mean_sent)\n",
    "    mae_no_sent, da_no_sent = getanalysis(act_values, mean_no_sent)\n",
    "\n",
    "    # Print metrics for the current ETF\n",
    "    print(etf , {\n",
    "        \"sent\": {\"mae\": mae_sent, \"da\": da_sent},\n",
    "        \"no_sent\": {\"mae\": mae_no_sent, \"da\": da_no_sent}\n",
    "    })\n",
    "    \n",
    "    # Return the results for this ETF\n",
    "    return {\n",
    "        \"act\" : act_values,\n",
    "        \"sent\": {\"predictions\": mean_sent, \"mae\": mae_sent, \"da\": da_sent},\n",
    "        \"no_sent\": {\"predictions\": mean_no_sent, \"mae\": mae_no_sent, \"da\": da_no_sent}\n",
    "    }\n",
    "\n",
    "# Loop through ETFs and aggregate results\n",
    "def run_all_etfs(etfs, model_type, sequence_size=sequence_size, cross_window=cross_window):\n",
    "    sent_results, no_sent_results = [], []\n",
    "    actual_array = []\n",
    "    \n",
    "    for etf in etfs:\n",
    "        print(f\"Training for ETF: {etf}\")\n",
    "        sent_cols = sent_dict['SENT']  # Columns for SENT model\n",
    "        no_sent_cols = sent_dict['NO_SENT']  # Columns for NO_SENT model\n",
    "\n",
    "        # Train and get results for the ETF\n",
    "        result = train(etf, sequence_size, cross_window, model_type, sent_cols, no_sent_cols)\n",
    "        \n",
    "        # Store the predictions and actual values\n",
    "        sent_results.append(result['sent']['predictions'])\n",
    "        no_sent_results.append(result['no_sent']['predictions'])\n",
    "        actual_array.append(result['act'])  # Collect actual values\n",
    "\n",
    "    # Concatenate results across all ETFs\n",
    "    sent_results = np.concatenate(sent_results, axis=0)\n",
    "    no_sent_results = np.concatenate(no_sent_results, axis=0)\n",
    "    actual_array = np.concatenate(actual_array, axis=0)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    mae_sent, da_sent = getanalysis(actual_array, sent_results)\n",
    "    mae_no_sent, da_no_sent = getanalysis(actual_array, no_sent_results)\n",
    "\n",
    "    # Print combined metrics\n",
    "    print(\"Combined results:\")\n",
    "    print(f\"SENT - MAE: {mae_sent}, DA: {da_sent}\")\n",
    "    print(f\"NO_SENT - MAE: {mae_no_sent}, DA: {da_no_sent}\")\n",
    "    \n",
    "    return sent_results, no_sent_results, actual_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646d778c-3fb7-4060-ac7e-a7eec3cdf3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/.pyenv/versions/3.12.5/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.01842574856570262\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.014933408262559258\n",
      "ICLN {'sent': {'mae': 0.01074380030257861, 'da': 0.496}, 'no_sent': {'mae': 0.010585142827722951, 'da': 0.516}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.012617999778623804\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.010511918916077336\n",
      "ICLN {'sent': {'mae': 0.0097266223567185, 'da': 0.568}, 'no_sent': {'mae': 0.007966012023201664, 'da': 0.652}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.008957975383652624\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.008128267721973587\n",
      "ICLN {'sent': {'mae': 0.006615554875908735, 'da': 0.66}, 'no_sent': {'mae': 0.005918889489135099, 'da': 0.692}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.007063050218623053\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.006441787318443295\n",
      "ICLN {'sent': {'mae': 0.005067542849193242, 'da': 0.744}, 'no_sent': {'mae': 0.004615526762363462, 'da': 0.76}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.006226234994624599\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.005864531283267872\n",
      "ICLN {'sent': {'mae': 0.004468779819529655, 'da': 0.748}, 'no_sent': {'mae': 0.004213245176261243, 'da': 0.764}}\n",
      "ICLN {'sent': {'mae': 0.005809019121041054, 'da': 0.481376}, 'no_sent': {'mae': 0.005656640242538155, 'da': 0.483168}}\n",
      "Training for ETF: PBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/.pyenv/versions/3.12.5/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.010289261504537963\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.009704964367397328\n",
      "PBD {'sent': {'mae': 0.007884581083497873, 'da': 0.52}, 'no_sent': {'mae': 0.007531563312248164, 'da': 0.588}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.008279032662333569\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.007475626207176083\n",
      "PBD {'sent': {'mae': 0.006336151516073403, 'da': 0.656}, 'no_sent': {'mae': 0.005784947052777913, 'da': 0.696}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.006925959488112204\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.006420821935807783\n",
      "PBD {'sent': {'mae': 0.005068044225813676, 'da': 0.728}, 'no_sent': {'mae': 0.004617214563263001, 'da': 0.756}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.006054599775383032\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.005845178247082035\n",
      "PBD {'sent': {'mae': 0.0044521923249736615, 'da': 0.76}, 'no_sent': {'mae': 0.004245594227718683, 'da': 0.784}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.005556428706490001\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.005437052967302268\n",
      "PBD {'sent': {'mae': 0.003976137396081072, 'da': 0.788}, 'no_sent': {'mae': 0.003795751635263856, 'da': 0.772}}\n",
      "PBD {'sent': {'mae': 0.004645476141068517, 'da': 0.503136}, 'no_sent': {'mae': 0.0043801309945245325, 'da': 0.498976}}\n",
      "Training for ETF: QCLN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/.pyenv/versions/3.12.5/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.020509911589793334\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.016559488108717706\n",
      "QCLN {'sent': {'mae': 0.015230774766330968, 'da': 0.464}, 'no_sent': {'mae': 0.012913688913438868, 'da': 0.568}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.014226723409950381\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.011655039286848011\n",
      "QCLN {'sent': {'mae': 0.010848854812408226, 'da': 0.6}, 'no_sent': {'mae': 0.009086159702541514, 'da': 0.64}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.010141859002104783\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.009273409196242373\n",
      "QCLN {'sent': {'mae': 0.007985418342442286, 'da': 0.644}, 'no_sent': {'mae': 0.007084632372503346, 'da': 0.712}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.009011395676494371\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.008480383683743568\n",
      "QCLN {'sent': {'mae': 0.006882329017214276, 'da': 0.728}, 'no_sent': {'mae': 0.0063106148906275856, 'da': 0.784}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.007801209431266928\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0072874463556318395\n",
      "QCLN {'sent': {'mae': 0.00567437389216545, 'da': 0.788}, 'no_sent': {'mae': 0.00532368224799359, 'da': 0.792}}\n",
      "QCLN {'sent': {'mae': 0.007566977988156853, 'da': 0.481184}, 'no_sent': {'mae': 0.006761069682397015, 'da': 0.488928}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.006007157750088808, DA: 0.4881671111111111\n",
      "NO_SENT - MAE: 0.005599280306486569, DA: 0.49037155555555556\n"
     ]
    }
   ],
   "source": [
    "model_type = 'cnnlstm'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5893a023-859e-468d-8683-54ce183200e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "model RMSE = 0.009826896494937355\n",
      "model RMSE = 0.009826896494937355\n",
      "ICLN {'sent': {'mae': 0.007641349786716184, 'da': 0.42}, 'no_sent': {'mae': 0.007641349786716184, 'da': 0.42}}\n",
      "model RMSE = 0.009826896494937355\n",
      "model RMSE = 0.009826896494937355\n",
      "ICLN {'sent': {'mae': 0.007641349786716184, 'da': 0.42}, 'no_sent': {'mae': 0.007641349786716184, 'da': 0.42}}\n",
      "model RMSE = 0.009826896494937355\n",
      "model RMSE = 0.009826896494937355\n",
      "ICLN {'sent': {'mae': 0.007641349786716184, 'da': 0.42}, 'no_sent': {'mae': 0.007641349786716184, 'da': 0.42}}\n",
      "model RMSE = 0.009826896494937355\n",
      "model RMSE = 0.009826896494937355\n",
      "ICLN {'sent': {'mae': 0.007641349786716184, 'da': 0.42}, 'no_sent': {'mae': 0.007641349786716184, 'da': 0.42}}\n",
      "model RMSE = 0.009826896494937355\n",
      "model RMSE = 0.009826896494937355\n",
      "ICLN {'sent': {'mae': 0.007641349786716184, 'da': 0.42}, 'no_sent': {'mae': 0.007641349786716184, 'da': 0.42}}\n",
      "ICLN {'sent': {'mae': 0.007641349786716184, 'da': 0.42}, 'no_sent': {'mae': 0.007641349786716184, 'da': 0.42}}\n",
      "Training for ETF: PBD\n",
      "model RMSE = 0.009892896803594474\n",
      "model RMSE = 0.009892896803594474\n",
      "PBD {'sent': {'mae': 0.007975929651694157, 'da': 0.38}, 'no_sent': {'mae': 0.007975929651694157, 'da': 0.38}}\n",
      "model RMSE = 0.009892896803594474\n",
      "model RMSE = 0.009892896803594474\n",
      "PBD {'sent': {'mae': 0.007975929651694157, 'da': 0.38}, 'no_sent': {'mae': 0.007975929651694157, 'da': 0.38}}\n",
      "model RMSE = 0.009892896803594474\n",
      "model RMSE = 0.009892896803594474\n",
      "PBD {'sent': {'mae': 0.007975929651694157, 'da': 0.38}, 'no_sent': {'mae': 0.007975929651694157, 'da': 0.38}}\n",
      "model RMSE = 0.009892896803594474\n",
      "model RMSE = 0.009892896803594474\n",
      "PBD {'sent': {'mae': 0.007975929651694157, 'da': 0.38}, 'no_sent': {'mae': 0.007975929651694157, 'da': 0.38}}\n",
      "model RMSE = 0.009892896803594474\n",
      "model RMSE = 0.009892896803594474\n",
      "PBD {'sent': {'mae': 0.007975929651694157, 'da': 0.38}, 'no_sent': {'mae': 0.007975929651694157, 'da': 0.38}}\n",
      "PBD {'sent': {'mae': 0.007975929651694157, 'da': 0.38}, 'no_sent': {'mae': 0.007975929651694157, 'da': 0.38}}\n",
      "Training for ETF: QCLN\n",
      "model RMSE = 0.013169472617812938\n",
      "model RMSE = 0.013169472617812938\n",
      "QCLN {'sent': {'mae': 0.009724828778083911, 'da': 0.572}, 'no_sent': {'mae': 0.009724828778083911, 'da': 0.572}}\n",
      "model RMSE = 0.013169472617812938\n",
      "model RMSE = 0.013169472617812938\n",
      "QCLN {'sent': {'mae': 0.009724828778083911, 'da': 0.572}, 'no_sent': {'mae': 0.009724828778083911, 'da': 0.572}}\n",
      "model RMSE = 0.013169472617812938\n",
      "model RMSE = 0.013169472617812938\n",
      "QCLN {'sent': {'mae': 0.009724828778083911, 'da': 0.572}, 'no_sent': {'mae': 0.009724828778083911, 'da': 0.572}}\n",
      "model RMSE = 0.013169472617812938\n",
      "model RMSE = 0.013169472617812938\n",
      "QCLN {'sent': {'mae': 0.009724828778083911, 'da': 0.572}, 'no_sent': {'mae': 0.009724828778083911, 'da': 0.572}}\n",
      "model RMSE = 0.013169472617812938\n",
      "model RMSE = 0.013169472617812938\n",
      "QCLN {'sent': {'mae': 0.009724828778083911, 'da': 0.572}, 'no_sent': {'mae': 0.009724828778083911, 'da': 0.572}}\n",
      "QCLN {'sent': {'mae': 0.009724828778083911, 'da': 0.572}, 'no_sent': {'mae': 0.009724828778083911, 'da': 0.572}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.008447369405498084, DA: 0.4537777777777778\n",
      "NO_SENT - MAE: 0.008447369405498084, DA: 0.4537777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 09:22:41.764454: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model_type = 'svr'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61e7c826-0ee3-437e-b21a-8d625a23b34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "model RMSE = 0.01000556820341184\n",
      "model RMSE = 0.01000556820341184\n",
      "ICLN {'sent': {'mae': 0.007553457904509896, 'da': 0.471968}, 'no_sent': {'mae': 0.007553457904509896, 'da': 0.471968}}\n",
      "model RMSE = 0.01000556820341184\n",
      "model RMSE = 0.01000556820341184\n",
      "ICLN {'sent': {'mae': 0.007553457904509896, 'da': 0.471968}, 'no_sent': {'mae': 0.007553457904509896, 'da': 0.471968}}\n",
      "model RMSE = 0.01000556820341184\n",
      "model RMSE = 0.01000556820341184\n",
      "ICLN {'sent': {'mae': 0.007553457904509896, 'da': 0.471968}, 'no_sent': {'mae': 0.007553457904509896, 'da': 0.471968}}\n",
      "model RMSE = 0.01000556820341184\n",
      "model RMSE = 0.01000556820341184\n",
      "ICLN {'sent': {'mae': 0.007553457904509896, 'da': 0.471968}, 'no_sent': {'mae': 0.007553457904509896, 'da': 0.471968}}\n",
      "model RMSE = 0.01000556820341184\n",
      "model RMSE = 0.01000556820341184\n",
      "ICLN {'sent': {'mae': 0.007553457904509896, 'da': 0.471968}, 'no_sent': {'mae': 0.007553457904509896, 'da': 0.471968}}\n",
      "ICLN {'sent': {'mae': 0.007553457904509896, 'da': 0.471968}, 'no_sent': {'mae': 0.007553457904509896, 'da': 0.471968}}\n",
      "Training for ETF: PBD\n",
      "model RMSE = 0.008490716312664072\n",
      "model RMSE = 0.008490716312664072\n",
      "PBD {'sent': {'mae': 0.006392065755365702, 'da': 0.503136}, 'no_sent': {'mae': 0.006392065755365702, 'da': 0.503136}}\n",
      "model RMSE = 0.008490716312664072\n",
      "model RMSE = 0.008490716312664072\n",
      "PBD {'sent': {'mae': 0.006392065755365702, 'da': 0.503136}, 'no_sent': {'mae': 0.006392065755365702, 'da': 0.503136}}\n",
      "model RMSE = 0.008490716312664072\n",
      "model RMSE = 0.008490716312664072\n",
      "PBD {'sent': {'mae': 0.006392065755365702, 'da': 0.503136}, 'no_sent': {'mae': 0.006392065755365702, 'da': 0.503136}}\n",
      "model RMSE = 0.008490716312664072\n",
      "model RMSE = 0.008490716312664072\n",
      "PBD {'sent': {'mae': 0.006392065755365702, 'da': 0.503136}, 'no_sent': {'mae': 0.006392065755365702, 'da': 0.503136}}\n",
      "model RMSE = 0.008490716312664072\n",
      "model RMSE = 0.008490716312664072\n",
      "PBD {'sent': {'mae': 0.006392065755365702, 'da': 0.503136}, 'no_sent': {'mae': 0.006392065755365702, 'da': 0.503136}}\n",
      "PBD {'sent': {'mae': 0.006392065755365702, 'da': 0.503136}, 'no_sent': {'mae': 0.006392065755365702, 'da': 0.503136}}\n",
      "Training for ETF: QCLN\n",
      "model RMSE = 0.013694027664092173\n",
      "model RMSE = 0.013694027664092173\n",
      "QCLN {'sent': {'mae': 0.010359217333212673, 'da': 0.47696}, 'no_sent': {'mae': 0.010359217333212673, 'da': 0.47696}}\n",
      "model RMSE = 0.013694027664092173\n",
      "model RMSE = 0.013694027664092173\n",
      "QCLN {'sent': {'mae': 0.010359217333212673, 'da': 0.47696}, 'no_sent': {'mae': 0.010359217333212673, 'da': 0.47696}}\n",
      "model RMSE = 0.013694027664092173\n",
      "model RMSE = 0.013694027664092173\n",
      "QCLN {'sent': {'mae': 0.010359217333212673, 'da': 0.47696}, 'no_sent': {'mae': 0.010359217333212673, 'da': 0.47696}}\n",
      "model RMSE = 0.013694027664092173\n",
      "model RMSE = 0.013694027664092173\n",
      "QCLN {'sent': {'mae': 0.010359217333212673, 'da': 0.47696}, 'no_sent': {'mae': 0.010359217333212673, 'da': 0.47696}}\n",
      "model RMSE = 0.013694027664092173\n",
      "model RMSE = 0.013694027664092173\n",
      "QCLN {'sent': {'mae': 0.010359217333212673, 'da': 0.47696}, 'no_sent': {'mae': 0.010359217333212673, 'da': 0.47696}}\n",
      "QCLN {'sent': {'mae': 0.010359217333212673, 'da': 0.47696}, 'no_sent': {'mae': 0.010359217333212673, 'da': 0.47696}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.008101580331029425, DA: 0.4822151111111111\n",
      "NO_SENT - MAE: 0.008101580331029425, DA: 0.4822151111111111\n"
     ]
    }
   ],
   "source": [
    "model_type = 'random_forest'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0b982b9-0329-4402-ab97-7a72579139b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "model RMSE = 0.009628014764278195\n",
      "model RMSE = 0.009628014764278195\n",
      "ICLN {'sent': {'mae': 0.007409198430752487, 'da': 0.464352}, 'no_sent': {'mae': 0.007409198430752487, 'da': 0.464352}}\n",
      "model RMSE = 0.009628014764278195\n",
      "model RMSE = 0.009628014764278195\n",
      "ICLN {'sent': {'mae': 0.007409198430752487, 'da': 0.464352}, 'no_sent': {'mae': 0.007409198430752487, 'da': 0.464352}}\n",
      "model RMSE = 0.009628014764278195\n",
      "model RMSE = 0.009628014764278195\n",
      "ICLN {'sent': {'mae': 0.007409198430752487, 'da': 0.464352}, 'no_sent': {'mae': 0.007409198430752487, 'da': 0.464352}}\n",
      "model RMSE = 0.009628014764278195\n",
      "model RMSE = 0.009628014764278195\n",
      "ICLN {'sent': {'mae': 0.007409198430752487, 'da': 0.464352}, 'no_sent': {'mae': 0.007409198430752487, 'da': 0.464352}}\n",
      "model RMSE = 0.009628014764278195\n",
      "model RMSE = 0.009628014764278195\n",
      "ICLN {'sent': {'mae': 0.007409198430752487, 'da': 0.464352}, 'no_sent': {'mae': 0.007409198430752487, 'da': 0.464352}}\n",
      "ICLN {'sent': {'mae': 0.007409198433690155, 'da': 0.464352}, 'no_sent': {'mae': 0.007409198433690155, 'da': 0.464352}}\n",
      "Training for ETF: PBD\n",
      "model RMSE = 0.008553520055639053\n",
      "model RMSE = 0.008553520055639053\n",
      "PBD {'sent': {'mae': 0.006402620468743251, 'da': 0.490656}, 'no_sent': {'mae': 0.006402620468743251, 'da': 0.490656}}\n",
      "model RMSE = 0.008553520055639053\n",
      "model RMSE = 0.008553520055639053\n",
      "PBD {'sent': {'mae': 0.006402620468743251, 'da': 0.490656}, 'no_sent': {'mae': 0.006402620468743251, 'da': 0.490656}}\n",
      "model RMSE = 0.008553520055639053\n",
      "model RMSE = 0.008553520055639053\n",
      "PBD {'sent': {'mae': 0.006402620468743251, 'da': 0.490656}, 'no_sent': {'mae': 0.006402620468743251, 'da': 0.490656}}\n",
      "model RMSE = 0.008553520055639053\n",
      "model RMSE = 0.008553520055639053\n",
      "PBD {'sent': {'mae': 0.006402620468743251, 'da': 0.490656}, 'no_sent': {'mae': 0.006402620468743251, 'da': 0.490656}}\n",
      "model RMSE = 0.008553520055639053\n",
      "model RMSE = 0.008553520055639053\n",
      "PBD {'sent': {'mae': 0.006402620468743251, 'da': 0.490656}, 'no_sent': {'mae': 0.006402620468743251, 'da': 0.490656}}\n",
      "PBD {'sent': {'mae': 0.006402620469970614, 'da': 0.490656}, 'no_sent': {'mae': 0.006402620469970614, 'da': 0.490656}}\n",
      "Training for ETF: QCLN\n",
      "model RMSE = 0.01296589523037235\n",
      "model RMSE = 0.01296589523037235\n",
      "QCLN {'sent': {'mae': 0.009783472135576137, 'da': 0.483296}, 'no_sent': {'mae': 0.009783472135576137, 'da': 0.483296}}\n",
      "model RMSE = 0.01296589523037235\n",
      "model RMSE = 0.01296589523037235\n",
      "QCLN {'sent': {'mae': 0.009783472135576137, 'da': 0.483296}, 'no_sent': {'mae': 0.009783472135576137, 'da': 0.483296}}\n",
      "model RMSE = 0.01296589523037235\n",
      "model RMSE = 0.01296589523037235\n",
      "QCLN {'sent': {'mae': 0.009783472135576137, 'da': 0.483296}, 'no_sent': {'mae': 0.009783472135576137, 'da': 0.483296}}\n",
      "model RMSE = 0.01296589523037235\n",
      "model RMSE = 0.01296589523037235\n",
      "QCLN {'sent': {'mae': 0.009783472135576137, 'da': 0.483296}, 'no_sent': {'mae': 0.009783472135576137, 'da': 0.483296}}\n",
      "model RMSE = 0.01296589523037235\n",
      "model RMSE = 0.01296589523037235\n",
      "QCLN {'sent': {'mae': 0.009783472135576137, 'da': 0.483296}, 'no_sent': {'mae': 0.009783472135576137, 'da': 0.483296}}\n",
      "QCLN {'sent': {'mae': 0.009783472134877645, 'da': 0.483296}, 'no_sent': {'mae': 0.009783472134877645, 'da': 0.483296}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.007865097012846139, DA: 0.4771448888888889\n",
      "NO_SENT - MAE: 0.007865097012846139, DA: 0.4771448888888889\n"
     ]
    }
   ],
   "source": [
    "model_type = 'xgboost'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcece44-fd78-437b-8515-d91e9f87a98a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "ICLN {'sent': {'mae': 0.007429468915579905, 'da': 0.471072}, 'no_sent': {'mae': 0.007429468915579905, 'da': 0.471072}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "ICLN {'sent': {'mae': 0.007429468915579905, 'da': 0.471072}, 'no_sent': {'mae': 0.007429468915579905, 'da': 0.471072}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "ICLN {'sent': {'mae': 0.007429468915579905, 'da': 0.471072}, 'no_sent': {'mae': 0.007429468915579905, 'da': 0.471072}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "ICLN {'sent': {'mae': 0.007429468915579905, 'da': 0.471072}, 'no_sent': {'mae': 0.007429468915579905, 'da': 0.471072}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000170\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0096765325419389\n",
      "ICLN {'sent': {'mae': 0.007429468915579905, 'da': 0.471072}, 'no_sent': {'mae': 0.007429468915579905, 'da': 0.471072}}\n",
      "ICLN {'sent': {'mae': 0.007429468915579905, 'da': 0.471072}, 'no_sent': {'mae': 0.007429468915579905, 'da': 0.471072}}\n",
      "Training for ETF: PBD\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "PBD {'sent': {'mae': 0.006466418441221324, 'da': 0.498144}, 'no_sent': {'mae': 0.006466418441221324, 'da': 0.498144}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "PBD {'sent': {'mae': 0.006466418441221324, 'da': 0.498144}, 'no_sent': {'mae': 0.006466418441221324, 'da': 0.498144}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "PBD {'sent': {'mae': 0.006466418441221324, 'da': 0.498144}, 'no_sent': {'mae': 0.006466418441221324, 'da': 0.498144}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "PBD {'sent': {'mae': 0.006466418441221324, 'da': 0.498144}, 'no_sent': {'mae': 0.006466418441221324, 'da': 0.498144}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.00858532825333235\n",
      "PBD {'sent': {'mae': 0.006466418441221324, 'da': 0.498144}, 'no_sent': {'mae': 0.006466418441221324, 'da': 0.498144}}\n",
      "PBD {'sent': {'mae': 0.006466418441221324, 'da': 0.498144}, 'no_sent': {'mae': 0.006466418441221324, 'da': 0.498144}}\n",
      "Training for ETF: QCLN\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "QCLN {'sent': {'mae': 0.00987047128646432, 'da': 0.481888}, 'no_sent': {'mae': 0.00987047128646432, 'da': 0.481888}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "QCLN {'sent': {'mae': 0.00987047128646432, 'da': 0.481888}, 'no_sent': {'mae': 0.00987047128646432, 'da': 0.481888}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "QCLN {'sent': {'mae': 0.00987047128646432, 'da': 0.481888}, 'no_sent': {'mae': 0.00987047128646432, 'da': 0.481888}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "QCLN {'sent': {'mae': 0.00987047128646432, 'da': 0.481888}, 'no_sent': {'mae': 0.00987047128646432, 'da': 0.481888}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.000021\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.013014773533372085\n",
      "QCLN {'sent': {'mae': 0.00987047128646432, 'da': 0.481888}, 'no_sent': {'mae': 0.00987047128646432, 'da': 0.481888}}\n",
      "QCLN {'sent': {'mae': 0.00987047128646432, 'da': 0.481888}, 'no_sent': {'mae': 0.00987047128646432, 'da': 0.481888}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.007922119547755183, DA: 0.4819946666666667\n",
      "NO_SENT - MAE: 0.007922119547755183, DA: 0.4819946666666667\n"
     ]
    }
   ],
   "source": [
    "model_type = 'lightgbm'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebb3bd09-f662-4062-a9c0-d011020a9cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "model RMSE = 0.009946770252609899\n",
      "model RMSE = 0.009946770252609899\n",
      "ICLN {'sent': {'mae': 0.007660721415739209, 'da': 0.475552}, 'no_sent': {'mae': 0.007660721415739209, 'da': 0.475552}}\n",
      "model RMSE = 0.009946770252609899\n",
      "model RMSE = 0.009946770252609899\n",
      "ICLN {'sent': {'mae': 0.007660721415739209, 'da': 0.475552}, 'no_sent': {'mae': 0.007660721415739209, 'da': 0.475552}}\n",
      "model RMSE = 0.009946770252609899\n",
      "model RMSE = 0.009946770252609899\n",
      "ICLN {'sent': {'mae': 0.007660721415739209, 'da': 0.475552}, 'no_sent': {'mae': 0.007660721415739209, 'da': 0.475552}}\n",
      "model RMSE = 0.009946770252609899\n",
      "model RMSE = 0.009946770252609899\n",
      "ICLN {'sent': {'mae': 0.007660721415739209, 'da': 0.475552}, 'no_sent': {'mae': 0.007660721415739209, 'da': 0.475552}}\n",
      "model RMSE = 0.009946770252609899\n",
      "model RMSE = 0.009946770252609899\n",
      "ICLN {'sent': {'mae': 0.007660721415739209, 'da': 0.475552}, 'no_sent': {'mae': 0.007660721415739209, 'da': 0.475552}}\n",
      "ICLN {'sent': {'mae': 0.007660721415739209, 'da': 0.475552}, 'no_sent': {'mae': 0.007660721415739209, 'da': 0.475552}}\n",
      "Training for ETF: PBD\n",
      "model RMSE = 0.008542280066620516\n",
      "model RMSE = 0.008542280066620516\n",
      "PBD {'sent': {'mae': 0.006515522687191493, 'da': 0.501472}, 'no_sent': {'mae': 0.006515522687191493, 'da': 0.501472}}\n",
      "model RMSE = 0.008542280066620516\n",
      "model RMSE = 0.008542280066620516\n",
      "PBD {'sent': {'mae': 0.006515522687191493, 'da': 0.501472}, 'no_sent': {'mae': 0.006515522687191493, 'da': 0.501472}}\n",
      "model RMSE = 0.008542280066620516\n",
      "model RMSE = 0.008542280066620516\n",
      "PBD {'sent': {'mae': 0.006515522687191493, 'da': 0.501472}, 'no_sent': {'mae': 0.006515522687191493, 'da': 0.501472}}\n",
      "model RMSE = 0.008542280066620516\n",
      "model RMSE = 0.008542280066620516\n",
      "PBD {'sent': {'mae': 0.006515522687191493, 'da': 0.501472}, 'no_sent': {'mae': 0.006515522687191493, 'da': 0.501472}}\n",
      "model RMSE = 0.008542280066620516\n",
      "model RMSE = 0.008542280066620516\n",
      "PBD {'sent': {'mae': 0.006515522687191493, 'da': 0.501472}, 'no_sent': {'mae': 0.006515522687191493, 'da': 0.501472}}\n",
      "PBD {'sent': {'mae': 0.006515522687191493, 'da': 0.501472}, 'no_sent': {'mae': 0.006515522687191493, 'da': 0.501472}}\n",
      "Training for ETF: QCLN\n",
      "model RMSE = 0.013148198553542371\n",
      "model RMSE = 0.013148198553542371\n",
      "QCLN {'sent': {'mae': 0.010056405016832273, 'da': 0.478368}, 'no_sent': {'mae': 0.010056405016832273, 'da': 0.478368}}\n",
      "model RMSE = 0.013148198553542371\n",
      "model RMSE = 0.013148198553542371\n",
      "QCLN {'sent': {'mae': 0.010056405016832273, 'da': 0.478368}, 'no_sent': {'mae': 0.010056405016832273, 'da': 0.478368}}\n",
      "model RMSE = 0.013148198553542371\n",
      "model RMSE = 0.013148198553542371\n",
      "QCLN {'sent': {'mae': 0.010056405016832273, 'da': 0.478368}, 'no_sent': {'mae': 0.010056405016832273, 'da': 0.478368}}\n",
      "model RMSE = 0.013148198553542371\n",
      "model RMSE = 0.013148198553542371\n",
      "QCLN {'sent': {'mae': 0.010056405016832273, 'da': 0.478368}, 'no_sent': {'mae': 0.010056405016832273, 'da': 0.478368}}\n",
      "model RMSE = 0.013148198553542371\n",
      "model RMSE = 0.013148198553542371\n",
      "QCLN {'sent': {'mae': 0.010056405016832273, 'da': 0.478368}, 'no_sent': {'mae': 0.010056405016832273, 'da': 0.478368}}\n",
      "QCLN {'sent': {'mae': 0.010056405016832273, 'da': 0.478368}, 'no_sent': {'mae': 0.010056405016832273, 'da': 0.478368}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.008077549706587656, DA: 0.48397866666666667\n",
      "NO_SENT - MAE: 0.008077549706587656, DA: 0.48397866666666667\n"
     ]
    }
   ],
   "source": [
    "model_type = 'catboost'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149179c-d59a-4455-9c95-97ff23f3234d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b826448-707d-417c-95b2-7fe0cd9f840e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
