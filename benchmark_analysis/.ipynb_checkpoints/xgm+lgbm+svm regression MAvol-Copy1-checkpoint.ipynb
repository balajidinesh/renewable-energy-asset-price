{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebbbfe8-5f9c-4e6a-a74d-b825824a84e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 09:01:11.801714: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 09:01:11.811258: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 09:01:11.814370: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 09:01:11.822309: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 09:01:12.458763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy.special import expit\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle as sklearn_shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, LSTM, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# from misc_modules import dm_test, plot_double_standard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f37ca-5b1f-409c-b2af-0a375ad37898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d41fe4-d030-459a-a604-695839bfc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "etfs = ['ICLN', 'PBD', 'QCLN']  # ETF symbols\n",
    "sequence_size = 4  # Number of time steps in sequence\n",
    "cross_window = 5  # Number of cross-validation windows\n",
    "\n",
    "lags = [1]\n",
    "predType = 'ahead_mvol'\n",
    "predLabel = 'Moving Avg Volatility'\n",
    "pred_size=250\n",
    "model_name = f'cnnlstm-{predType}'\n",
    "\n",
    "save_path = '../results'\n",
    "data_path = '../data'\n",
    "\n",
    "sent_dict =  {\n",
    "    'SENT': ['MAvol', 'GT_VAL_SENT_MVOL', 'INV_VAL_SENT_MVOL'],\n",
    "    'NO_SENT': ['MAvol']\n",
    "}\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0beab59-331f-4a68-aea8-56b34bbf5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_loss(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "\n",
    "class model:\n",
    "    def __init__(self, model_type, input_shape=None):\n",
    "        self.model_type = model_type\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._choose_model()\n",
    "\n",
    "    def _choose_model(self):\n",
    "        \"\"\"Choose and instantiate the model based on the provided model type.\"\"\"\n",
    "        if self.model_type == 'svr':\n",
    "            return SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "        elif self.model_type == 'random_forest':\n",
    "            return RandomForestRegressor(n_estimators=100, max_depth=None, min_samples_split=2, random_state=42)\n",
    "        elif self.model_type == 'xgboost':\n",
    "            return xgb.XGBRegressor(learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8, random_state=42)\n",
    "        elif self.model_type == 'lightgbm':\n",
    "            return lgb.LGBMRegressor(num_leaves=31, learning_rate=0.01, n_estimators=100, bagging_fraction=0.8, random_state=42)\n",
    "        elif self.model_type == 'catboost':\n",
    "            return CatBoostRegressor(iterations=100, depth=6, learning_rate=0.1, verbose=0, random_state=42)\n",
    "        elif self.model_type == 'cnnlstm':\n",
    "            if self.input_shape is None:\n",
    "                raise ValueError(\"input_shape must be provided for cnnlstm model.\")\n",
    "            return self._build_cnn_lstm_model()\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid model type: {self.model_type}\")\n",
    "\n",
    "    def _build_cnn_lstm_model(self):\n",
    "        \"\"\"Build the CNN-LSTM model for time series or sequence data.\"\"\"\n",
    "        Timesteps, No_Features = self.input_shape\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(Timesteps, No_Features)))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(LSTM(32, activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(8))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss=root_mean_squared_loss, metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X_train, y_train,epochs=100, batch_size=32, validation_split=0.2,shuffle=True):\n",
    "        \"\"\"Fit the model depending on the type.\"\"\"\n",
    "\n",
    "        \n",
    "        if self.model_type in ['svr', 'random_forest', 'xgboost', 'lightgbm', 'catboost']:\n",
    "            if shuffle:\n",
    "                X_train, y_train = sklearn_shuffle(X_train, y_train, random_state=42)\n",
    "            self.model.fit(X_train, y_train)\n",
    "        elif self.model_type == 'cnnlstm':\n",
    "            X_train = X_train.reshape(-1, *self.input_shape)\n",
    "            # early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            self.model.fit(X_train, y_train, epochs=epochs, verbose=False,shuffle=shuffle)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using the chosen model.\"\"\"\n",
    "        if self.model_type in ['svr', 'random_forest', 'xgboost', 'lightgbm', 'catboost']:\n",
    "            return self.model.predict(X)\n",
    "        elif self.model_type == 'cnnlstm':\n",
    "            X = X.reshape(-1, *self.input_shape)\n",
    "            return self.model.predict(X, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6dab091-e5cb-4d89-b6df-c6b29d36b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(file, lag):\n",
    "    data = pd.read_csv(f\"{data_path}/{file}/{file}_INPUT.csv\")\n",
    "    data['ahead_Return'] = data['log_return'].shift(-1 * lag)\n",
    "    data['ahead_vol'] = data['Garchvol'].shift(-1 * lag)\n",
    "    data['ahead_mvol'] = data['MAvol'].shift(-1*(lag))\n",
    "    data = data[:-1 * lag]  # Drop rows corresponding to lag\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "# Create sequences of input data\n",
    "def sequences(X, y, timesteps):\n",
    "    \"\"\"\n",
    "    Generate sequences for time series models.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    alpha, beta = [], []\n",
    "    n = timesteps\n",
    "    for i in range(X.shape[0]):\n",
    "        if i < n - 1:\n",
    "            continue\n",
    "        alpha.append(X[i - (n - 1):i + 1])\n",
    "        beta.append(y[i])\n",
    "\n",
    "    return np.asarray(alpha), np.asarray(beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d22e89-e6f7-4e26-ad03-448313810971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define helper functions\n",
    "def concat_results_and_mean(arrays):\n",
    "    \"\"\"\n",
    "    Concatenate and compute mean across all arrays.\n",
    "    \"\"\"\n",
    "    new_arrays = [np.array(single_arr).reshape(-1) for single_arr in arrays]\n",
    "    mean_array = np.mean(new_arrays, axis=0)\n",
    "    return mean_array\n",
    "\n",
    "def getanalysis(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate MAE and Directional Accuracy.\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    da = directional_accuracy(y_true, y_pred)\n",
    "    return mae, da\n",
    "\n",
    "def directional_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Directional Accuracy (DA).\n",
    "    \"\"\"\n",
    "\n",
    "    if predType == 'ahead_Return' :\n",
    "        correct_directions = np.sign(y_true) == np.sign(y_pred)\n",
    "    else :\n",
    "        correct_directions = np.sign(y_true[1:] - y_true[:-1]) == np.sign(y_pred[1:] - y_pred[:-1])\n",
    "    \n",
    "    return np.mean(correct_directions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f94621-45ab-4b05-8f5d-120bd87444fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_etfs(etfs, predType, data_path):\n",
    "    for etf in etfs:\n",
    "        # Fetch the data\n",
    "        data = fetch(etf, 1)\n",
    "        \n",
    "        # Display basic info about the dataset\n",
    "        # print(f\"\\nBasic Info for {etf}:\\n\", data.info())\n",
    "\n",
    "        # Display descriptive statistics for the specified prediction type\n",
    "        print(f\"\\nDescriptive Statistics for '{predType}' column in {etf}:\\n\")\n",
    "        stats = pd.DataFrame(data[predType]).describe()\n",
    "        print(stats)\n",
    "\n",
    "        # Visualize distribution of the specified prediction type using a histogram\n",
    "        plt.figure(figsize=(7, 6))\n",
    "        sns.histplot(data[predType], kde=True, color='blue')\n",
    "        plt.title(f'Distribution of {predType} for {etf}')\n",
    "        plt.show()\n",
    "\n",
    "        # Visualize boxplot for the specified prediction type\n",
    "        plt.figure(figsize=(7, 6))\n",
    "        sns.boxplot(x=data[predType], color='blue')\n",
    "        plt.title(f'Boxplot for {predType} for {etf}')\n",
    "        plt.show()\n",
    "\n",
    "# Call the function\n",
    "# analyze_etfs(etfs, predType, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8824cfaf-ca5f-4670-9cb1-f31ae70074e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_train(model,X ,Y , train_window=500, test_window = 10,  pred_size=pred_size,sequence_size=sequence_size) :\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # .reshape(X[:-pred_size].shape[0],1,sequence_size,-1)\n",
    "    model.fit(X[:-pred_size], Y[:-pred_size], epochs=200)\n",
    "\n",
    "    if model.model_type == 'cnnlstm' : \n",
    "        # tw_start and tw_end , means training window start index and end index\n",
    "        for tw_end in range(X.shape[0] - pred_size, X.shape[0], 10):\n",
    "            tw_start = tw_end - train_window\n",
    "    \n",
    "            X_train, y_train = X[tw_start:tw_end], Y[tw_start:tw_end]\n",
    "            # X_train = X_train.reshape(X_train.shape[0],1,sequence_size,-1)\n",
    "            model.fit(X_train, y_train, epochs=50)\n",
    "    \n",
    "            test = X[tw_end:tw_end+test_window]  #.reshape(X[tw_end:tw_end+test_window].shape[0],1,sequence_size,-1)\n",
    "            preds = model.predict(test)\n",
    "            result.extend(preds)\n",
    "            print(tw_end, end=' ')\n",
    "    else :\n",
    "        result.extend(model.predict(X[-pred_size:]))\n",
    "\n",
    "    rmse_val = root_mean_squared_loss(Y[-pred_size:].reshape(-1), np.array(result).reshape(-1))\n",
    "\n",
    "    print(f\"model RMSE = {rmse_val}\")\n",
    "\n",
    "    return np.array(result), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf286399-6ea4-4e59-b2a2-0c1b290b84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(etf, sequence_size, cross_window, model_type, sent_cols, no_sent_cols):\n",
    "    lag = 1\n",
    "    data = fetch(etf, lag) \n",
    "\n",
    "    SENT_X = data[sent_cols]\n",
    "    # Y = data[[predType]]  \n",
    "    NO_SENT_X = data[no_sent_cols]\n",
    "    \n",
    "    Y = np.array(data[[predType]])  \n",
    "\n",
    "    SENT_X, SENT_Y = sequences(SENT_X, Y, timesteps=sequence_size)\n",
    "    NO_SENT_X, NO_SENT_Y = sequences(NO_SENT_X, Y, timesteps=sequence_size)\n",
    "\n",
    "\n",
    "    sent_shape = SENT_X.shape[1:]\n",
    "    no_sent_shape = NO_SENT_X.shape[1:]\n",
    "\n",
    "    sent_model = model(model_type,sent_shape)\n",
    "    no_sent_model = model(model_type,no_sent_shape)\n",
    "\n",
    "        # machine learning regression models\n",
    "    SENT_X = SENT_X.reshape(SENT_X.shape[0], -1)\n",
    "    NO_SENT_X = NO_SENT_X.reshape(NO_SENT_X.shape[0], -1)\n",
    "    SENT_Y = SENT_Y.reshape(-1,)\n",
    "    NO_SENT_Y = NO_SENT_Y.reshape(-1,)\n",
    "\n",
    "\n",
    "    Y_PRED = Y[-pred_size:]  # Actual values for the prediction window\n",
    "    sent_predictions, no_sent_predictions = [], []\n",
    "    act_values = Y_PRED  # Actual values for this window\n",
    "    \n",
    "    # Perform cross validation over cross_window\n",
    "    for k in range(cross_window):\n",
    "\n",
    "        # Train and predict for SENT model\n",
    "        sent_pred, sent_model = sliding_window_train(sent_model,SENT_X, SENT_Y)\n",
    "        no_sent_pred, no_sent_model = sliding_window_train(sent_model,SENT_X, SENT_Y)\n",
    "\n",
    "        sent_predictions.append(sent_pred)\n",
    "        no_sent_predictions.append(no_sent_pred)\n",
    "\n",
    "        mae_sent_temp, da_sent_temp = getanalysis(act_values, sent_pred)\n",
    "        mae_no_sent_temp, da_no_sent_temp = getanalysis(act_values, no_sent_pred)\n",
    "    \n",
    "        # Print metrics for the current ETF\n",
    "        print(etf , {\n",
    "            \"sent\": {\"mae\": mae_sent_temp, \"da\": da_sent_temp},\n",
    "            \"no_sent\": {\"mae\": mae_no_sent_temp, \"da\": da_no_sent_temp}\n",
    "        })\n",
    "    \n",
    "\n",
    "    mean_sent = concat_results_and_mean(sent_predictions)  # Mean predictions for SENT\n",
    "    mean_no_sent = concat_results_and_mean(no_sent_predictions)  # Mean predictions for NO_SENT\n",
    "\n",
    "    # Get prediction metrics for SENT and NO_SENT\n",
    "    mae_sent, da_sent = getanalysis(act_values, mean_sent)\n",
    "    mae_no_sent, da_no_sent = getanalysis(act_values, mean_no_sent)\n",
    "\n",
    "    # Print metrics for the current ETF\n",
    "    print(etf , {\n",
    "        \"sent\": {\"mae\": mae_sent, \"da\": da_sent},\n",
    "        \"no_sent\": {\"mae\": mae_no_sent, \"da\": da_no_sent}\n",
    "    })\n",
    "    \n",
    "    # Return the results for this ETF\n",
    "    return {\n",
    "        \"act\" : act_values,\n",
    "        \"sent\": {\"predictions\": mean_sent, \"mae\": mae_sent, \"da\": da_sent},\n",
    "        \"no_sent\": {\"predictions\": mean_no_sent, \"mae\": mae_no_sent, \"da\": da_no_sent}\n",
    "    }\n",
    "\n",
    "# Loop through ETFs and aggregate results\n",
    "def run_all_etfs(etfs, model_type, sequence_size=sequence_size, cross_window=cross_window):\n",
    "    sent_results, no_sent_results = [], []\n",
    "    actual_array = []\n",
    "    \n",
    "    for etf in etfs:\n",
    "        print(f\"Training for ETF: {etf}\")\n",
    "        sent_cols = sent_dict['SENT']  # Columns for SENT model\n",
    "        no_sent_cols = sent_dict['NO_SENT']  # Columns for NO_SENT model\n",
    "\n",
    "        # Train and get results for the ETF\n",
    "        result = train(etf, sequence_size, cross_window, model_type, sent_cols, no_sent_cols)\n",
    "        \n",
    "        # Store the predictions and actual values\n",
    "        sent_results.append(result['sent']['predictions'])\n",
    "        no_sent_results.append(result['no_sent']['predictions'])\n",
    "        actual_array.append(result['act'])  # Collect actual values\n",
    "\n",
    "    # Concatenate results across all ETFs\n",
    "    sent_results = np.concatenate(sent_results, axis=0)\n",
    "    no_sent_results = np.concatenate(no_sent_results, axis=0)\n",
    "    actual_array = np.concatenate(actual_array, axis=0)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    mae_sent, da_sent = getanalysis(actual_array, sent_results)\n",
    "    mae_no_sent, da_no_sent = getanalysis(actual_array, no_sent_results)\n",
    "\n",
    "    # Print combined metrics\n",
    "    print(\"Combined results:\")\n",
    "    print(f\"SENT - MAE: {mae_sent}, DA: {da_sent}\")\n",
    "    print(f\"NO_SENT - MAE: {mae_no_sent}, DA: {da_no_sent}\")\n",
    "    \n",
    "    return sent_results, no_sent_results, actual_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646d778c-3fb7-4060-ac7e-a7eec3cdf3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/.pyenv/versions/3.12.5/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727148701.205770    5563 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1727148701.241702    5563 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1727148701.241740    5563 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1727148701.247016    5563 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1727148701.247062    5563 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1727148701.247078    5563 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1727148701.343652    5563 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1727148701.343715    5563 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-24 09:01:41.343722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1727148701.343757    5563 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-24 09:01:41.343769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5519 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727148726.151891   22142 service.cc:146] XLA service 0x7f3b1400ddd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727148726.151935   22142 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3050, Compute Capability 8.6\n",
      "2024-09-24 09:02:06.187662: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-24 09:02:06.324178: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-24 09:02:07.676045: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,1,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,1,4]{3,2,1,0}, f32[32,3,1,1]{3,2,1,0}, f32[32]{0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-09-24 09:02:10.270414: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.59444832s\n",
      "Trying algorithm eng0{} for conv (f32[32,32,1,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,1,4]{3,2,1,0}, f32[32,3,1,1]{3,2,1,0}, f32[32]{0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "I0000 00:00:1727148730.902284   22142 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-09-24 09:02:12.301803: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=3,k3=0} for conv (f32[3,32,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,18,1,4]{3,2,1,0}, f32[32,18,1,4]{3,2,1,0}), window={size=1x4}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-09-24 09:02:15.699153: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.397443522s\n",
      "Trying algorithm eng28{k2=3,k3=0} for conv (f32[3,32,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,18,1,4]{3,2,1,0}, f32[32,18,1,4]{3,2,1,0}), window={size=1x4}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.00065881076016993\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006106957229861775\n",
      "ICLN {'sent': {'mae': 0.0004634282425780374, 'da': 0.5060240963855421}, 'no_sent': {'mae': 0.0004242406515490745, 'da': 0.4859437751004016}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.00061103372338893\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006257057564903135\n",
      "ICLN {'sent': {'mae': 0.00041113075354797435, 'da': 0.46987951807228917}, 'no_sent': {'mae': 0.00044269983008678074, 'da': 0.4979919678714859}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0005969582357805396\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.000602124153342706\n",
      "ICLN {'sent': {'mae': 0.0004136847484602137, 'da': 0.5140562248995983}, 'no_sent': {'mae': 0.00042033260060830657, 'da': 0.5100401606425703}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006186308391165652\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.000640568294146347\n",
      "ICLN {'sent': {'mae': 0.0004172372957586022, 'da': 0.5180722891566265}, 'no_sent': {'mae': 0.0004573948031666125, 'da': 0.4979919678714859}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006075159254433476\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006178157531366741\n",
      "ICLN {'sent': {'mae': 0.00042017477021976426, 'da': 0.5100401606425703}, 'no_sent': {'mae': 0.0004361558617178305, 'da': 0.5100401606425703}}\n",
      "ICLN {'sent': {'mae': 0.00037884551394872846, 'da': 0.5045241205787003}, 'no_sent': {'mae': 0.00038781625220123795, 'da': 0.503427364074773}}\n",
      "Training for ETF: PBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/.pyenv/versions/3.12.5/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006996533869888387\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006371012842980203\n",
      "PBD {'sent': {'mae': 0.00047899437715538207, 'da': 0.5662650602409639}, 'no_sent': {'mae': 0.0004012684512023379, 'da': 0.5542168674698795}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006927255104500485\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006363219689167936\n",
      "PBD {'sent': {'mae': 0.0004813901688004804, 'da': 0.5502008032128514}, 'no_sent': {'mae': 0.0004089148073895279, 'da': 0.5502008032128514}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.000658529338490115\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006561310739602381\n",
      "PBD {'sent': {'mae': 0.0004357041843516954, 'da': 0.5622489959839357}, 'no_sent': {'mae': 0.00042684890570896574, 'da': 0.5622489959839357}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006118964544061158\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006480237480406222\n",
      "PBD {'sent': {'mae': 0.0004008794652985433, 'da': 0.5502008032128514}, 'no_sent': {'mae': 0.00046388585074032534, 'da': 0.5542168674698795}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006677299343464697\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0006417582440577508\n",
      "PBD {'sent': {'mae': 0.0004663793648241058, 'da': 0.5341365461847389}, 'no_sent': {'mae': 0.00041863112001486375, 'da': 0.5341365461847389}}\n",
      "PBD {'sent': {'mae': 0.00039174574135315333, 'da': 0.5013306236996178}, 'no_sent': {'mae': 0.0003726366488171133, 'da': 0.5008467605361204}}\n",
      "Training for ETF: QCLN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/.pyenv/versions/3.12.5/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0008367882311380822\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0007944087820282402\n",
      "QCLN {'sent': {'mae': 0.0005801724601214591, 'da': 0.5220883534136547}, 'no_sent': {'mae': 0.0005488556411703968, 'da': 0.4859437751004016}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0008412691942876017\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0008239683751983317\n",
      "QCLN {'sent': {'mae': 0.0005857589589416217, 'da': 0.5060240963855421}, 'no_sent': {'mae': 0.0005544797243612949, 'da': 0.4899598393574297}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0008003203045600186\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.000779456118032436\n",
      "QCLN {'sent': {'mae': 0.0005506485389471116, 'da': 0.4979919678714859}, 'no_sent': {'mae': 0.0005333924323470601, 'da': 0.4979919678714859}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0008138228380319233\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0007554967951747947\n",
      "QCLN {'sent': {'mae': 0.0005747368071417638, 'da': 0.5261044176706827}, 'no_sent': {'mae': 0.0005000927893904771, 'da': 0.5220883534136547}}\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0007649966761477823\n",
      "1234 1244 1254 1264 1274 1284 1294 1304 1314 1324 1334 1344 1354 1364 1374 1384 1394 1404 1414 1424 1434 1444 1454 1464 1474 model RMSE = 0.0007339182212759303\n",
      "QCLN {'sent': {'mae': 0.0005199245039062444, 'da': 0.5220883534136547}, 'no_sent': {'mae': 0.0004984565002279584, 'da': 0.5421686746987951}}\n",
      "QCLN {'sent': {'mae': 0.0004819901598388323, 'da': 0.5031531749487912}, 'no_sent': {'mae': 0.00047429842518047834, 'da': 0.5031531749487912}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.000417527138380238, DA: 0.5027869825543984\n",
      "NO_SENT - MAE: 0.0004115837753996098, DA: 0.5022201386450291\n"
     ]
    }
   ],
   "source": [
    "model_type = 'cnnlstm'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5893a023-859e-468d-8683-54ce183200e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "model RMSE = 0.005866702139063677\n",
      "model RMSE = 0.005866702139063677\n",
      "ICLN {'sent': {'mae': 0.005364992184297444, 'da': 0.0}, 'no_sent': {'mae': 0.005364992184297444, 'da': 0.0}}\n",
      "model RMSE = 0.005866702139063677\n",
      "model RMSE = 0.005866702139063677\n",
      "ICLN {'sent': {'mae': 0.005364992184297444, 'da': 0.0}, 'no_sent': {'mae': 0.005364992184297444, 'da': 0.0}}\n",
      "model RMSE = 0.005866702139063677\n",
      "model RMSE = 0.005866702139063677\n",
      "ICLN {'sent': {'mae': 0.005364992184297444, 'da': 0.0}, 'no_sent': {'mae': 0.005364992184297444, 'da': 0.0}}\n",
      "model RMSE = 0.005866702139063677\n",
      "model RMSE = 0.005866702139063677\n",
      "ICLN {'sent': {'mae': 0.005364992184297444, 'da': 0.0}, 'no_sent': {'mae': 0.005364992184297444, 'da': 0.0}}\n",
      "model RMSE = 0.005866702139063677\n",
      "model RMSE = 0.005866702139063677\n",
      "ICLN {'sent': {'mae': 0.005364992184297444, 'da': 0.0}, 'no_sent': {'mae': 0.005364992184297444, 'da': 0.0}}\n",
      "ICLN {'sent': {'mae': 0.005364992184297443, 'da': 0.0}, 'no_sent': {'mae': 0.005364992184297443, 'da': 0.0}}\n",
      "Training for ETF: PBD\n",
      "model RMSE = 0.00574919807177142\n",
      "model RMSE = 0.00574919807177142\n",
      "PBD {'sent': {'mae': 0.005236412301191853, 'da': 0.0}, 'no_sent': {'mae': 0.005236412301191853, 'da': 0.0}}\n",
      "model RMSE = 0.00574919807177142\n",
      "model RMSE = 0.00574919807177142\n",
      "PBD {'sent': {'mae': 0.005236412301191853, 'da': 0.0}, 'no_sent': {'mae': 0.005236412301191853, 'da': 0.0}}\n",
      "model RMSE = 0.00574919807177142\n",
      "model RMSE = 0.00574919807177142\n",
      "PBD {'sent': {'mae': 0.005236412301191853, 'da': 0.0}, 'no_sent': {'mae': 0.005236412301191853, 'da': 0.0}}\n",
      "model RMSE = 0.00574919807177142\n",
      "model RMSE = 0.00574919807177142\n",
      "PBD {'sent': {'mae': 0.005236412301191853, 'da': 0.0}, 'no_sent': {'mae': 0.005236412301191853, 'da': 0.0}}\n",
      "model RMSE = 0.00574919807177142\n",
      "model RMSE = 0.00574919807177142\n",
      "PBD {'sent': {'mae': 0.005236412301191853, 'da': 0.0}, 'no_sent': {'mae': 0.005236412301191853, 'da': 0.0}}\n",
      "PBD {'sent': {'mae': 0.005236412301191853, 'da': 0.0}, 'no_sent': {'mae': 0.005236412301191853, 'da': 0.0}}\n",
      "Training for ETF: QCLN\n",
      "model RMSE = 0.00493145770302853\n",
      "model RMSE = 0.00493145770302853\n",
      "QCLN {'sent': {'mae': 0.0043592513731584995, 'da': 0.0}, 'no_sent': {'mae': 0.0043592513731584995, 'da': 0.0}}\n",
      "model RMSE = 0.00493145770302853\n",
      "model RMSE = 0.00493145770302853\n",
      "QCLN {'sent': {'mae': 0.0043592513731584995, 'da': 0.0}, 'no_sent': {'mae': 0.0043592513731584995, 'da': 0.0}}\n",
      "model RMSE = 0.00493145770302853\n",
      "model RMSE = 0.00493145770302853\n",
      "QCLN {'sent': {'mae': 0.0043592513731584995, 'da': 0.0}, 'no_sent': {'mae': 0.0043592513731584995, 'da': 0.0}}\n",
      "model RMSE = 0.00493145770302853\n",
      "model RMSE = 0.00493145770302853\n",
      "QCLN {'sent': {'mae': 0.0043592513731584995, 'da': 0.0}, 'no_sent': {'mae': 0.0043592513731584995, 'da': 0.0}}\n",
      "model RMSE = 0.00493145770302853\n",
      "model RMSE = 0.00493145770302853\n",
      "QCLN {'sent': {'mae': 0.0043592513731584995, 'da': 0.0}, 'no_sent': {'mae': 0.0043592513731584995, 'da': 0.0}}\n",
      "QCLN {'sent': {'mae': 0.0043592513731584995, 'da': 0.0}, 'no_sent': {'mae': 0.0043592513731584995, 'da': 0.0}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.004986885286215932, DA: 0.0013351134846461949\n",
      "NO_SENT - MAE: 0.004986885286215932, DA: 0.0013351134846461949\n"
     ]
    }
   ],
   "source": [
    "model_type = 'svr'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e7c826-0ee3-437e-b21a-8d625a23b34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "model RMSE = 0.0006407131569737165\n",
      "model RMSE = 0.0006407131569737165\n",
      "ICLN {'sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}, 'no_sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}}\n",
      "model RMSE = 0.0006407131569737165\n",
      "model RMSE = 0.0006407131569737165\n",
      "ICLN {'sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}, 'no_sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}}\n",
      "model RMSE = 0.0006407131569737165\n",
      "model RMSE = 0.0006407131569737165\n",
      "ICLN {'sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}, 'no_sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}}\n",
      "model RMSE = 0.0006407131569737165\n",
      "model RMSE = 0.0006407131569737165\n",
      "ICLN {'sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}, 'no_sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}}\n",
      "model RMSE = 0.0006407131569737165\n",
      "model RMSE = 0.0006407131569737165\n",
      "ICLN {'sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}, 'no_sent': {'mae': 0.00044410770896157115, 'da': 0.5023306075708456}}\n",
      "ICLN {'sent': {'mae': 0.0004441077089615711, 'da': 0.5023306075708456}, 'no_sent': {'mae': 0.0004441077089615711, 'da': 0.5023306075708456}}\n",
      "Training for ETF: PBD\n",
      "model RMSE = 0.000658721862336097\n",
      "model RMSE = 0.000658721862336097\n",
      "PBD {'sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}, 'no_sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}}\n",
      "model RMSE = 0.000658721862336097\n",
      "model RMSE = 0.000658721862336097\n",
      "PBD {'sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}, 'no_sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}}\n",
      "model RMSE = 0.000658721862336097\n",
      "model RMSE = 0.000658721862336097\n",
      "PBD {'sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}, 'no_sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}}\n",
      "model RMSE = 0.000658721862336097\n",
      "model RMSE = 0.000658721862336097\n",
      "PBD {'sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}, 'no_sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}}\n",
      "model RMSE = 0.000658721862336097\n",
      "model RMSE = 0.000658721862336097\n",
      "PBD {'sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}, 'no_sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}}\n",
      "PBD {'sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}, 'no_sent': {'mae': 0.0004136234479581976, 'da': 0.5013306236996178}}\n",
      "Training for ETF: QCLN\n",
      "model RMSE = 0.0007926464522102848\n",
      "model RMSE = 0.0007926464522102848\n",
      "QCLN {'sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}, 'no_sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}}\n",
      "model RMSE = 0.0007926464522102848\n",
      "model RMSE = 0.0007926464522102848\n",
      "QCLN {'sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}, 'no_sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}}\n",
      "model RMSE = 0.0007926464522102848\n",
      "model RMSE = 0.0007926464522102848\n",
      "QCLN {'sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}, 'no_sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}}\n",
      "model RMSE = 0.0007926464522102848\n",
      "model RMSE = 0.0007926464522102848\n",
      "QCLN {'sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}, 'no_sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}}\n",
      "model RMSE = 0.0007926464522102848\n",
      "model RMSE = 0.0007926464522102848\n",
      "QCLN {'sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}, 'no_sent': {'mae': 0.0005180261058565863, 'da': 0.5001854808793407}}\n",
      "QCLN {'sent': {'mae': 0.0005180261058565864, 'da': 0.5001854808793407}, 'no_sent': {'mae': 0.0005180261058565864, 'da': 0.5001854808793407}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.000458585754258785, DA: 0.5012753987960806\n",
      "NO_SENT - MAE: 0.000458585754258785, DA: 0.5012753987960806\n"
     ]
    }
   ],
   "source": [
    "model_type = 'random_forest'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0b982b9-0329-4402-ab97-7a72579139b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "model RMSE = 0.0015598218323550342\n",
      "model RMSE = 0.0015598218323550342\n",
      "ICLN {'sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}, 'no_sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}}\n",
      "model RMSE = 0.0015598218323550342\n",
      "model RMSE = 0.0015598218323550342\n",
      "ICLN {'sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}, 'no_sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}}\n",
      "model RMSE = 0.0015598218323550342\n",
      "model RMSE = 0.0015598218323550342\n",
      "ICLN {'sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}, 'no_sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}}\n",
      "model RMSE = 0.0015598218323550342\n",
      "model RMSE = 0.0015598218323550342\n",
      "ICLN {'sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}, 'no_sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}}\n",
      "model RMSE = 0.0015598218323550342\n",
      "model RMSE = 0.0015598218323550342\n",
      "ICLN {'sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}, 'no_sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}}\n",
      "ICLN {'sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}, 'no_sent': {'mae': 0.0012967243438303403, 'da': 0.47399235496201675}}\n",
      "Training for ETF: PBD\n",
      "model RMSE = 0.001639638228060286\n",
      "model RMSE = 0.001639638228060286\n",
      "PBD {'sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}, 'no_sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}}\n",
      "model RMSE = 0.001639638228060286\n",
      "model RMSE = 0.001639638228060286\n",
      "PBD {'sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}, 'no_sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}}\n",
      "model RMSE = 0.001639638228060286\n",
      "model RMSE = 0.001639638228060286\n",
      "PBD {'sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}, 'no_sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}}\n",
      "model RMSE = 0.001639638228060286\n",
      "model RMSE = 0.001639638228060286\n",
      "PBD {'sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}, 'no_sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}}\n",
      "model RMSE = 0.001639638228060286\n",
      "model RMSE = 0.001639638228060286\n",
      "PBD {'sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}, 'no_sent': {'mae': 0.0013938843295113888, 'da': 0.41863840905791844}}\n",
      "PBD {'sent': {'mae': 0.0013938842736320343, 'da': 0.41863840905791844}, 'no_sent': {'mae': 0.0013938842736320343, 'da': 0.41863840905791844}}\n",
      "Training for ETF: QCLN\n",
      "model RMSE = 0.001725810717283205\n",
      "model RMSE = 0.001725810717283205\n",
      "QCLN {'sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}, 'no_sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}}\n",
      "model RMSE = 0.001725810717283205\n",
      "model RMSE = 0.001725810717283205\n",
      "QCLN {'sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}, 'no_sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}}\n",
      "model RMSE = 0.001725810717283205\n",
      "model RMSE = 0.001725810717283205\n",
      "QCLN {'sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}, 'no_sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}}\n",
      "model RMSE = 0.001725810717283205\n",
      "model RMSE = 0.001725810717283205\n",
      "QCLN {'sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}, 'no_sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}}\n",
      "model RMSE = 0.001725810717283205\n",
      "model RMSE = 0.001725810717283205\n",
      "QCLN {'sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}, 'no_sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}}\n",
      "QCLN {'sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}, 'no_sent': {'mae': 0.0013815199928210466, 'da': 0.4732504314446541}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.0013573762034278071, DA: 0.4550063190618199\n",
      "NO_SENT - MAE: 0.0013573762034278071, DA: 0.4550063190618199\n"
     ]
    }
   ],
   "source": [
    "model_type = 'xgboost'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bcece44-fd78-437b-8515-d91e9f87a98a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "ICLN {'sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}, 'no_sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "ICLN {'sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}, 'no_sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "ICLN {'sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}, 'no_sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "ICLN {'sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}, 'no_sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.012043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.001515136248497955\n",
      "ICLN {'sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}, 'no_sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}}\n",
      "ICLN {'sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}, 'no_sent': {'mae': 0.00127277989303824, 'da': 0.4776858437767133}}\n",
      "Training for ETF: PBD\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "PBD {'sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}, 'no_sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "PBD {'sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}, 'no_sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "PBD {'sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}, 'no_sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "PBD {'sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}, 'no_sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.010718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0015756211987984425\n",
      "PBD {'sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}, 'no_sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}}\n",
      "PBD {'sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}, 'no_sent': {'mae': 0.0013437552307659837, 'da': 0.4160739342913824}}\n",
      "Training for ETF: QCLN\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "QCLN {'sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}, 'no_sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "QCLN {'sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}, 'no_sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "QCLN {'sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}, 'no_sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "QCLN {'sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}, 'no_sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}}\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1234, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.013132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "model RMSE = 0.0016522245780788325\n",
      "QCLN {'sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}, 'no_sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}}\n",
      "QCLN {'sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}, 'no_sent': {'mae': 0.0013354300113344814, 'da': 0.46883114788471153}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.0013173217117129017, DA: 0.45415605319776614\n",
      "NO_SENT - MAE: 0.0013173217117129017, DA: 0.45415605319776614\n"
     ]
    }
   ],
   "source": [
    "model_type = 'lightgbm'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb3bd09-f662-4062-a9c0-d011020a9cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ETF: ICLN\n",
      "model RMSE = 0.0006632660872133102\n",
      "model RMSE = 0.0006632660872133102\n",
      "ICLN {'sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}, 'no_sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}}\n",
      "model RMSE = 0.0006632660872133102\n",
      "model RMSE = 0.0006632660872133102\n",
      "ICLN {'sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}, 'no_sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}}\n",
      "model RMSE = 0.0006632660872133102\n",
      "model RMSE = 0.0006632660872133102\n",
      "ICLN {'sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}, 'no_sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}}\n",
      "model RMSE = 0.0006632660872133102\n",
      "model RMSE = 0.0006632660872133102\n",
      "ICLN {'sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}, 'no_sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}}\n",
      "model RMSE = 0.0006632660872133102\n",
      "model RMSE = 0.0006632660872133102\n",
      "ICLN {'sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}, 'no_sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}}\n",
      "ICLN {'sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}, 'no_sent': {'mae': 0.00045172996204461693, 'da': 0.5028789858228093}}\n",
      "Training for ETF: PBD\n",
      "model RMSE = 0.0007008579729238307\n",
      "model RMSE = 0.0007008579729238307\n",
      "PBD {'sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}, 'no_sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}}\n",
      "model RMSE = 0.0007008579729238307\n",
      "model RMSE = 0.0007008579729238307\n",
      "PBD {'sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}, 'no_sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}}\n",
      "model RMSE = 0.0007008579729238307\n",
      "model RMSE = 0.0007008579729238307\n",
      "PBD {'sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}, 'no_sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}}\n",
      "model RMSE = 0.0007008579729238307\n",
      "model RMSE = 0.0007008579729238307\n",
      "PBD {'sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}, 'no_sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}}\n",
      "model RMSE = 0.0007008579729238307\n",
      "model RMSE = 0.0007008579729238307\n",
      "PBD {'sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}, 'no_sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}}\n",
      "PBD {'sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}, 'no_sent': {'mae': 0.00047652102970954465, 'da': 0.5027822131901099}}\n",
      "Training for ETF: QCLN\n",
      "model RMSE = 0.0008213534565003756\n",
      "model RMSE = 0.0008213534565003756\n",
      "QCLN {'sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}, 'no_sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}}\n",
      "model RMSE = 0.0008213534565003756\n",
      "model RMSE = 0.0008213534565003756\n",
      "QCLN {'sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}, 'no_sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}}\n",
      "model RMSE = 0.0008213534565003756\n",
      "model RMSE = 0.0008213534565003756\n",
      "QCLN {'sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}, 'no_sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}}\n",
      "model RMSE = 0.0008213534565003756\n",
      "model RMSE = 0.0008213534565003756\n",
      "QCLN {'sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}, 'no_sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}}\n",
      "model RMSE = 0.0008213534565003756\n",
      "model RMSE = 0.0008213534565003756\n",
      "QCLN {'sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}, 'no_sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}}\n",
      "QCLN {'sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}, 'no_sent': {'mae': 0.0005361642178860649, 'da': 0.5016693279140659}}\n",
      "Combined results:\n",
      "SENT - MAE: 0.0004881384032134088, DA: 0.5024090866148189\n",
      "NO_SENT - MAE: 0.0004881384032134088, DA: 0.5024090866148189\n"
     ]
    }
   ],
   "source": [
    "model_type = 'catboost'\n",
    "\n",
    "sent_results, no_sent_results, actual_array = run_all_etfs(etfs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149179c-d59a-4455-9c95-97ff23f3234d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b826448-707d-417c-95b2-7fe0cd9f840e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
